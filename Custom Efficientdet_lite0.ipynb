{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIYiLcwo6lvA"
      },
      "outputs": [],
      "source": [
        "!pip install  tflite-model-maker\n",
        "!pip install  pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_nRg0sL6h35"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56cIsfwK5YQY"
      },
      "outputs": [],
      "source": [
        "#save final weights to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"lfDO94JkXbo8aZZzOHky\")\n",
        "project = rf.workspace(\"fruits-lggth\").project(\"fruits_yolov5\")\n",
        "dataset = project.version(6).download(\"voc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6V3ujkn4q8U6",
        "outputId": "94c1887b-c8f2-466a-e676-bf119235d527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-0.2.21-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 919 kB/s \n",
            "\u001b[?25hRequirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n",
            "Collecting urllib3==1.26.6\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 36.1 MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting certifi==2021.5.30\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 68.3 MB/s \n",
            "\u001b[?25hCollecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 64.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->roboflow) (2.1.1)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=1586c0c8d0773a8d59530c8176162606d8e59fd44b097a80e507fe10d3f1e9f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: urllib3, certifi, requests, pyparsing, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tflite-model-maker 0.4.2 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\u001b[0m\n",
            "Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-2.28.1 requests-toolbelt-0.10.1 roboflow-0.2.21 urllib3-1.26.6 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cycler",
                  "pyparsing",
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Fruits_yolov5-6 to voc: 100% [108624174 / 108624174] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Fruits_yolov5-6 in voc:: 100%|██████████| 5707/5707 [00:01<00:00, 2979.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrXwrqhL1Yhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63225774-1c4e-4c99-fe78-af1ffc84f3a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'apple', 2: 'apricot', 3: 'banana', 4: 'grapefruit', 5: 'lemon', 6: 'mango', 7: 'melon', 8: 'orange', 9: 'pear', 10: 'persimmone', 11: 'pineapple', 12: 'plum', 13: 'pomegranade', 14: 'watermelon'}\n",
            "Train dataset contains 1996 images\n"
          ]
        }
      ],
      "source": [
        "# Paths pointing to training and validation data respectively. Images and xml annotations are in the same location\n",
        "tr_image_dir= '/content/Fruits_yolov5-6/train'\n",
        "tr_image_annotations= '/content/Fruits_yolov5-6/train'\n",
        "val_image_dir='/content/Fruits_yolov5-6/valid'\n",
        "test_image_dir= '/content/Fruits_yolov5-6/test'\n",
        "\n",
        "label_map={1:'apple', 2:'apricot',3:'banana',4:'grapefruit',5:'lemon',6:'mango',7:'melon',8:'orange',9:'pear',10:'persimmone',11:'pineapple',12:'plum',13:'pomegranade',14:'watermelon'}\n",
        "print(label_map)\n",
        "\n",
        "# Load data. Data is loaded as tfrecord and stored in the cache_dir location, for fast future use. \n",
        "train_ds = object_detector.DataLoader.from_pascal_voc(images_dir=tr_image_dir,\n",
        "                                                      annotations_dir= tr_image_dir,\n",
        "                                                      label_map=label_map\n",
        "                                                     )\n",
        "# Load validation subset.\n",
        "val_ds = object_detector.DataLoader.from_pascal_voc(images_dir=val_image_dir,\n",
        "                                                      annotations_dir= val_image_dir,\n",
        "                                                      label_map=label_map,\n",
        "                                                     )\n",
        "# Load validation subset.\n",
        "test_ds = object_detector.DataLoader.from_pascal_voc(images_dir=test_image_dir,\n",
        "                                                      annotations_dir= test_image_dir,\n",
        "                                                      label_map=label_map,\n",
        "                                                     )\n",
        "\n",
        "print(\"Train dataset contains {} images\".format(train_ds.__len__()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtdZ-JDwMimd"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('efficientdet_lite0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwlYdTcg63xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2249b6c-afe6-42a5-b3c0-c705f30edbde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "249/249 [==============================] - 125s 354ms/step - det_loss: 1.3823 - cls_loss: 0.9967 - box_loss: 0.0077 - reg_l2_loss: 0.0652 - loss: 1.4475 - learning_rate: 0.0090 - gradient_norm: 1.7521 - val_det_loss: 1.1800 - val_cls_loss: 0.8386 - val_box_loss: 0.0068 - val_reg_l2_loss: 0.0653 - val_loss: 1.2452\n",
            "Epoch 2/100\n",
            "249/249 [==============================] - 73s 295ms/step - det_loss: 1.0169 - cls_loss: 0.7527 - box_loss: 0.0053 - reg_l2_loss: 0.0653 - loss: 1.0822 - learning_rate: 0.0100 - gradient_norm: 2.1692 - val_det_loss: 1.0123 - val_cls_loss: 0.7067 - val_box_loss: 0.0061 - val_reg_l2_loss: 0.0654 - val_loss: 1.0777\n",
            "Epoch 3/100\n",
            "249/249 [==============================] - 73s 293ms/step - det_loss: 0.9025 - cls_loss: 0.6677 - box_loss: 0.0047 - reg_l2_loss: 0.0654 - loss: 0.9680 - learning_rate: 0.0100 - gradient_norm: 2.2076 - val_det_loss: 0.9808 - val_cls_loss: 0.7075 - val_box_loss: 0.0055 - val_reg_l2_loss: 0.0655 - val_loss: 1.0463\n",
            "Epoch 4/100\n",
            "249/249 [==============================] - 79s 317ms/step - det_loss: 0.8310 - cls_loss: 0.6064 - box_loss: 0.0045 - reg_l2_loss: 0.0656 - loss: 0.8965 - learning_rate: 0.0100 - gradient_norm: 2.3824 - val_det_loss: 0.9014 - val_cls_loss: 0.5891 - val_box_loss: 0.0062 - val_reg_l2_loss: 0.0657 - val_loss: 0.9671\n",
            "Epoch 5/100\n",
            "249/249 [==============================] - 115s 463ms/step - det_loss: 0.7810 - cls_loss: 0.5673 - box_loss: 0.0043 - reg_l2_loss: 0.0658 - loss: 0.8467 - learning_rate: 0.0099 - gradient_norm: 2.5587 - val_det_loss: 0.9267 - val_cls_loss: 0.6072 - val_box_loss: 0.0064 - val_reg_l2_loss: 0.0659 - val_loss: 0.9926\n",
            "Epoch 6/100\n",
            "249/249 [==============================] - 76s 305ms/step - det_loss: 0.7524 - cls_loss: 0.5459 - box_loss: 0.0041 - reg_l2_loss: 0.0660 - loss: 0.8184 - learning_rate: 0.0099 - gradient_norm: 2.6175 - val_det_loss: 0.8555 - val_cls_loss: 0.5705 - val_box_loss: 0.0057 - val_reg_l2_loss: 0.0661 - val_loss: 0.9216\n",
            "Epoch 7/100\n",
            "249/249 [==============================] - 76s 305ms/step - det_loss: 0.7281 - cls_loss: 0.5220 - box_loss: 0.0041 - reg_l2_loss: 0.0662 - loss: 0.7943 - learning_rate: 0.0099 - gradient_norm: 2.6642 - val_det_loss: 0.8346 - val_cls_loss: 0.5421 - val_box_loss: 0.0058 - val_reg_l2_loss: 0.0663 - val_loss: 0.9009\n",
            "Epoch 8/100\n",
            "249/249 [==============================] - 73s 293ms/step - det_loss: 0.6985 - cls_loss: 0.5016 - box_loss: 0.0039 - reg_l2_loss: 0.0664 - loss: 0.7649 - learning_rate: 0.0099 - gradient_norm: 2.7193 - val_det_loss: 0.6737 - val_cls_loss: 0.4551 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0666 - val_loss: 0.7402\n",
            "Epoch 9/100\n",
            "249/249 [==============================] - 75s 302ms/step - det_loss: 0.6874 - cls_loss: 0.4924 - box_loss: 0.0039 - reg_l2_loss: 0.0667 - loss: 0.7541 - learning_rate: 0.0098 - gradient_norm: 2.7810 - val_det_loss: 1.0474 - val_cls_loss: 0.7003 - val_box_loss: 0.0069 - val_reg_l2_loss: 0.0668 - val_loss: 1.1142\n",
            "Epoch 10/100\n",
            "249/249 [==============================] - 103s 412ms/step - det_loss: 0.6637 - cls_loss: 0.4715 - box_loss: 0.0038 - reg_l2_loss: 0.0669 - loss: 0.7306 - learning_rate: 0.0098 - gradient_norm: 2.7044 - val_det_loss: 0.7491 - val_cls_loss: 0.5049 - val_box_loss: 0.0049 - val_reg_l2_loss: 0.0670 - val_loss: 0.8161\n",
            "Epoch 11/100\n",
            "249/249 [==============================] - 72s 290ms/step - det_loss: 0.6408 - cls_loss: 0.4556 - box_loss: 0.0037 - reg_l2_loss: 0.0671 - loss: 0.7079 - learning_rate: 0.0097 - gradient_norm: 2.7442 - val_det_loss: 0.6876 - val_cls_loss: 0.4759 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0673 - val_loss: 0.7549\n",
            "Epoch 12/100\n",
            "249/249 [==============================] - 78s 314ms/step - det_loss: 0.6288 - cls_loss: 0.4453 - box_loss: 0.0037 - reg_l2_loss: 0.0674 - loss: 0.6962 - learning_rate: 0.0097 - gradient_norm: 2.8039 - val_det_loss: 0.6877 - val_cls_loss: 0.4499 - val_box_loss: 0.0048 - val_reg_l2_loss: 0.0675 - val_loss: 0.7552\n",
            "Epoch 13/100\n",
            "249/249 [==============================] - 73s 291ms/step - det_loss: 0.6312 - cls_loss: 0.4470 - box_loss: 0.0037 - reg_l2_loss: 0.0677 - loss: 0.6989 - learning_rate: 0.0096 - gradient_norm: 2.8014 - val_det_loss: 0.8866 - val_cls_loss: 0.5994 - val_box_loss: 0.0057 - val_reg_l2_loss: 0.0678 - val_loss: 0.9544\n",
            "Epoch 14/100\n",
            "249/249 [==============================] - 72s 290ms/step - det_loss: 0.6053 - cls_loss: 0.4243 - box_loss: 0.0036 - reg_l2_loss: 0.0679 - loss: 0.6732 - learning_rate: 0.0095 - gradient_norm: 2.7311 - val_det_loss: 0.7341 - val_cls_loss: 0.4700 - val_box_loss: 0.0053 - val_reg_l2_loss: 0.0680 - val_loss: 0.8021\n",
            "Epoch 15/100\n",
            "249/249 [==============================] - 107s 428ms/step - det_loss: 0.5921 - cls_loss: 0.4159 - box_loss: 0.0035 - reg_l2_loss: 0.0681 - loss: 0.6603 - learning_rate: 0.0095 - gradient_norm: 2.7525 - val_det_loss: 0.8315 - val_cls_loss: 0.5960 - val_box_loss: 0.0047 - val_reg_l2_loss: 0.0683 - val_loss: 0.8998\n",
            "Epoch 16/100\n",
            "249/249 [==============================] - 73s 292ms/step - det_loss: 0.5934 - cls_loss: 0.4153 - box_loss: 0.0036 - reg_l2_loss: 0.0684 - loss: 0.6618 - learning_rate: 0.0094 - gradient_norm: 2.9186 - val_det_loss: 0.5939 - val_cls_loss: 0.3616 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0685 - val_loss: 0.6624\n",
            "Epoch 17/100\n",
            "249/249 [==============================] - 73s 294ms/step - det_loss: 0.5749 - cls_loss: 0.4018 - box_loss: 0.0035 - reg_l2_loss: 0.0686 - loss: 0.6436 - learning_rate: 0.0093 - gradient_norm: 2.7728 - val_det_loss: 0.6889 - val_cls_loss: 0.4041 - val_box_loss: 0.0057 - val_reg_l2_loss: 0.0687 - val_loss: 0.7577\n",
            "Epoch 18/100\n",
            "249/249 [==============================] - 78s 313ms/step - det_loss: 0.5783 - cls_loss: 0.4015 - box_loss: 0.0035 - reg_l2_loss: 0.0689 - loss: 0.6472 - learning_rate: 0.0092 - gradient_norm: 2.9607 - val_det_loss: 0.6506 - val_cls_loss: 0.4357 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0690 - val_loss: 0.7196\n",
            "Epoch 19/100\n",
            "249/249 [==============================] - 73s 292ms/step - det_loss: 0.5659 - cls_loss: 0.3922 - box_loss: 0.0035 - reg_l2_loss: 0.0691 - loss: 0.6350 - learning_rate: 0.0092 - gradient_norm: 2.6890 - val_det_loss: 0.6536 - val_cls_loss: 0.4489 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0692 - val_loss: 0.7228\n",
            "Epoch 20/100\n",
            "249/249 [==============================] - 102s 409ms/step - det_loss: 0.5533 - cls_loss: 0.3820 - box_loss: 0.0034 - reg_l2_loss: 0.0693 - loss: 0.6226 - learning_rate: 0.0091 - gradient_norm: 2.7285 - val_det_loss: 0.7044 - val_cls_loss: 0.3824 - val_box_loss: 0.0064 - val_reg_l2_loss: 0.0694 - val_loss: 0.7738\n",
            "Epoch 21/100\n",
            "249/249 [==============================] - 78s 315ms/step - det_loss: 0.5360 - cls_loss: 0.3682 - box_loss: 0.0034 - reg_l2_loss: 0.0695 - loss: 0.6055 - learning_rate: 0.0090 - gradient_norm: 2.8029 - val_det_loss: 0.5461 - val_cls_loss: 0.3460 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0696 - val_loss: 0.6157\n",
            "Epoch 22/100\n",
            "249/249 [==============================] - 74s 296ms/step - det_loss: 0.5340 - cls_loss: 0.3669 - box_loss: 0.0033 - reg_l2_loss: 0.0697 - loss: 0.6036 - learning_rate: 0.0089 - gradient_norm: 2.7439 - val_det_loss: 0.5697 - val_cls_loss: 0.3519 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0698 - val_loss: 0.6395\n",
            "Epoch 23/100\n",
            "249/249 [==============================] - 74s 298ms/step - det_loss: 0.5366 - cls_loss: 0.3670 - box_loss: 0.0034 - reg_l2_loss: 0.0699 - loss: 0.6065 - learning_rate: 0.0088 - gradient_norm: 2.8472 - val_det_loss: 0.7378 - val_cls_loss: 0.4764 - val_box_loss: 0.0052 - val_reg_l2_loss: 0.0700 - val_loss: 0.8078\n",
            "Epoch 24/100\n",
            "249/249 [==============================] - 80s 320ms/step - det_loss: 0.5186 - cls_loss: 0.3550 - box_loss: 0.0033 - reg_l2_loss: 0.0701 - loss: 0.5887 - learning_rate: 0.0087 - gradient_norm: 2.7881 - val_det_loss: 0.5972 - val_cls_loss: 0.3255 - val_box_loss: 0.0054 - val_reg_l2_loss: 0.0702 - val_loss: 0.6674\n",
            "Epoch 25/100\n",
            "249/249 [==============================] - 101s 406ms/step - det_loss: 0.5155 - cls_loss: 0.3527 - box_loss: 0.0033 - reg_l2_loss: 0.0703 - loss: 0.5858 - learning_rate: 0.0086 - gradient_norm: 2.8187 - val_det_loss: 0.5058 - val_cls_loss: 0.3006 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0704 - val_loss: 0.5762\n",
            "Epoch 26/100\n",
            "249/249 [==============================] - 74s 296ms/step - det_loss: 0.5089 - cls_loss: 0.3481 - box_loss: 0.0032 - reg_l2_loss: 0.0705 - loss: 0.5793 - learning_rate: 0.0085 - gradient_norm: 2.8470 - val_det_loss: 0.6054 - val_cls_loss: 0.3852 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0706 - val_loss: 0.6760\n",
            "Epoch 27/100\n",
            "249/249 [==============================] - 77s 311ms/step - det_loss: 0.5053 - cls_loss: 0.3433 - box_loss: 0.0032 - reg_l2_loss: 0.0707 - loss: 0.5760 - learning_rate: 0.0083 - gradient_norm: 2.9001 - val_det_loss: 0.5815 - val_cls_loss: 0.3368 - val_box_loss: 0.0049 - val_reg_l2_loss: 0.0708 - val_loss: 0.6523\n",
            "Epoch 28/100\n",
            "249/249 [==============================] - 73s 292ms/step - det_loss: 0.4993 - cls_loss: 0.3409 - box_loss: 0.0032 - reg_l2_loss: 0.0709 - loss: 0.5702 - learning_rate: 0.0082 - gradient_norm: 2.8399 - val_det_loss: 0.5720 - val_cls_loss: 0.3706 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0710 - val_loss: 0.6430\n",
            "Epoch 29/100\n",
            "249/249 [==============================] - 74s 296ms/step - det_loss: 0.5054 - cls_loss: 0.3439 - box_loss: 0.0032 - reg_l2_loss: 0.0711 - loss: 0.5765 - learning_rate: 0.0081 - gradient_norm: 2.9762 - val_det_loss: 0.4418 - val_cls_loss: 0.2582 - val_box_loss: 0.0037 - val_reg_l2_loss: 0.0712 - val_loss: 0.5129\n",
            "Epoch 30/100\n",
            "249/249 [==============================] - 104s 417ms/step - det_loss: 0.4784 - cls_loss: 0.3224 - box_loss: 0.0031 - reg_l2_loss: 0.0712 - loss: 0.5496 - learning_rate: 0.0080 - gradient_norm: 2.7645 - val_det_loss: 0.4759 - val_cls_loss: 0.2741 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0713 - val_loss: 0.5472\n",
            "Epoch 31/100\n",
            "249/249 [==============================] - 73s 292ms/step - det_loss: 0.4886 - cls_loss: 0.3319 - box_loss: 0.0031 - reg_l2_loss: 0.0714 - loss: 0.5600 - learning_rate: 0.0078 - gradient_norm: 2.9436 - val_det_loss: 0.5689 - val_cls_loss: 0.3670 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0715 - val_loss: 0.6404\n",
            "Epoch 32/100\n",
            "249/249 [==============================] - 71s 287ms/step - det_loss: 0.4741 - cls_loss: 0.3199 - box_loss: 0.0031 - reg_l2_loss: 0.0716 - loss: 0.5457 - learning_rate: 0.0077 - gradient_norm: 2.7206 - val_det_loss: 0.5241 - val_cls_loss: 0.3363 - val_box_loss: 0.0038 - val_reg_l2_loss: 0.0716 - val_loss: 0.5958\n",
            "Epoch 33/100\n",
            "249/249 [==============================] - 77s 311ms/step - det_loss: 0.4797 - cls_loss: 0.3229 - box_loss: 0.0031 - reg_l2_loss: 0.0717 - loss: 0.5514 - learning_rate: 0.0076 - gradient_norm: 2.7620 - val_det_loss: 0.5395 - val_cls_loss: 0.2861 - val_box_loss: 0.0051 - val_reg_l2_loss: 0.0718 - val_loss: 0.6113\n",
            "Epoch 34/100\n",
            "249/249 [==============================] - 72s 288ms/step - det_loss: 0.4643 - cls_loss: 0.3112 - box_loss: 0.0031 - reg_l2_loss: 0.0718 - loss: 0.5361 - learning_rate: 0.0074 - gradient_norm: 2.6962 - val_det_loss: 0.6214 - val_cls_loss: 0.3940 - val_box_loss: 0.0045 - val_reg_l2_loss: 0.0719 - val_loss: 0.6933\n",
            "Epoch 35/100\n",
            "249/249 [==============================] - 100s 402ms/step - det_loss: 0.4612 - cls_loss: 0.3140 - box_loss: 0.0029 - reg_l2_loss: 0.0720 - loss: 0.5332 - learning_rate: 0.0073 - gradient_norm: 2.7371 - val_det_loss: 0.4650 - val_cls_loss: 0.2874 - val_box_loss: 0.0036 - val_reg_l2_loss: 0.0720 - val_loss: 0.5370\n",
            "Epoch 36/100\n",
            "249/249 [==============================] - 78s 314ms/step - det_loss: 0.4509 - cls_loss: 0.3031 - box_loss: 0.0030 - reg_l2_loss: 0.0721 - loss: 0.5230 - learning_rate: 0.0071 - gradient_norm: 2.8411 - val_det_loss: 0.4940 - val_cls_loss: 0.2979 - val_box_loss: 0.0039 - val_reg_l2_loss: 0.0721 - val_loss: 0.5662\n",
            "Epoch 37/100\n",
            "249/249 [==============================] - 72s 291ms/step - det_loss: 0.4452 - cls_loss: 0.2970 - box_loss: 0.0030 - reg_l2_loss: 0.0722 - loss: 0.5174 - learning_rate: 0.0070 - gradient_norm: 2.6937 - val_det_loss: 0.5319 - val_cls_loss: 0.2713 - val_box_loss: 0.0052 - val_reg_l2_loss: 0.0722 - val_loss: 0.6042\n",
            "Epoch 38/100\n",
            "249/249 [==============================] - 72s 290ms/step - det_loss: 0.4369 - cls_loss: 0.2892 - box_loss: 0.0030 - reg_l2_loss: 0.0723 - loss: 0.5092 - learning_rate: 0.0069 - gradient_norm: 2.4406 - val_det_loss: 0.5271 - val_cls_loss: 0.3061 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0723 - val_loss: 0.5994\n",
            "Epoch 39/100\n",
            "249/249 [==============================] - 75s 303ms/step - det_loss: 0.4352 - cls_loss: 0.2888 - box_loss: 0.0029 - reg_l2_loss: 0.0724 - loss: 0.5076 - learning_rate: 0.0067 - gradient_norm: 2.6843 - val_det_loss: 0.4897 - val_cls_loss: 0.2896 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0724 - val_loss: 0.5621\n",
            "Epoch 40/100\n",
            "249/249 [==============================] - 102s 408ms/step - det_loss: 0.4334 - cls_loss: 0.2904 - box_loss: 0.0029 - reg_l2_loss: 0.0725 - loss: 0.5059 - learning_rate: 0.0066 - gradient_norm: 2.7984 - val_det_loss: 0.5176 - val_cls_loss: 0.2977 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0725 - val_loss: 0.5901\n",
            "Epoch 41/100\n",
            "249/249 [==============================] - 72s 287ms/step - det_loss: 0.4413 - cls_loss: 0.2939 - box_loss: 0.0029 - reg_l2_loss: 0.0725 - loss: 0.5139 - learning_rate: 0.0064 - gradient_norm: 2.7468 - val_det_loss: 0.4819 - val_cls_loss: 0.2617 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0726 - val_loss: 0.5545\n",
            "Epoch 42/100\n",
            "249/249 [==============================] - 74s 299ms/step - det_loss: 0.4233 - cls_loss: 0.2805 - box_loss: 0.0029 - reg_l2_loss: 0.0726 - loss: 0.4959 - learning_rate: 0.0063 - gradient_norm: 2.5657 - val_det_loss: 0.4839 - val_cls_loss: 0.2754 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0726 - val_loss: 0.5565\n",
            "Epoch 43/100\n",
            "249/249 [==============================] - 74s 296ms/step - det_loss: 0.4184 - cls_loss: 0.2744 - box_loss: 0.0029 - reg_l2_loss: 0.0727 - loss: 0.4911 - learning_rate: 0.0061 - gradient_norm: 2.6530 - val_det_loss: 0.4102 - val_cls_loss: 0.2284 - val_box_loss: 0.0036 - val_reg_l2_loss: 0.0727 - val_loss: 0.4829\n",
            "Epoch 44/100\n",
            "249/249 [==============================] - 72s 288ms/step - det_loss: 0.4145 - cls_loss: 0.2751 - box_loss: 0.0028 - reg_l2_loss: 0.0727 - loss: 0.4872 - learning_rate: 0.0059 - gradient_norm: 2.6853 - val_det_loss: 0.5475 - val_cls_loss: 0.3148 - val_box_loss: 0.0047 - val_reg_l2_loss: 0.0728 - val_loss: 0.6202\n",
            "Epoch 45/100\n",
            "249/249 [==============================] - 98s 392ms/step - det_loss: 0.4065 - cls_loss: 0.2678 - box_loss: 0.0028 - reg_l2_loss: 0.0728 - loss: 0.4793 - learning_rate: 0.0058 - gradient_norm: 2.5737 - val_det_loss: 0.6495 - val_cls_loss: 0.3699 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0728 - val_loss: 0.7223\n",
            "Epoch 46/100\n",
            "249/249 [==============================] - 78s 314ms/step - det_loss: 0.4079 - cls_loss: 0.2685 - box_loss: 0.0028 - reg_l2_loss: 0.0728 - loss: 0.4807 - learning_rate: 0.0056 - gradient_norm: 2.6879 - val_det_loss: 0.5172 - val_cls_loss: 0.3157 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0729 - val_loss: 0.5901\n",
            "Epoch 47/100\n",
            "249/249 [==============================] - 73s 292ms/step - det_loss: 0.4029 - cls_loss: 0.2657 - box_loss: 0.0027 - reg_l2_loss: 0.0729 - loss: 0.4758 - learning_rate: 0.0055 - gradient_norm: 2.6258 - val_det_loss: 0.4468 - val_cls_loss: 0.2529 - val_box_loss: 0.0039 - val_reg_l2_loss: 0.0729 - val_loss: 0.5197\n",
            "Epoch 48/100\n",
            "249/249 [==============================] - 72s 291ms/step - det_loss: 0.4079 - cls_loss: 0.2704 - box_loss: 0.0027 - reg_l2_loss: 0.0729 - loss: 0.4808 - learning_rate: 0.0053 - gradient_norm: 2.7312 - val_det_loss: 0.4806 - val_cls_loss: 0.2444 - val_box_loss: 0.0047 - val_reg_l2_loss: 0.0730 - val_loss: 0.5535\n",
            "Epoch 49/100\n",
            "249/249 [==============================] - 77s 311ms/step - det_loss: 0.3871 - cls_loss: 0.2530 - box_loss: 0.0027 - reg_l2_loss: 0.0730 - loss: 0.4601 - learning_rate: 0.0052 - gradient_norm: 2.4923 - val_det_loss: 0.4737 - val_cls_loss: 0.2460 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0730 - val_loss: 0.5467\n",
            "Epoch 50/100\n",
            "249/249 [==============================] - 98s 396ms/step - det_loss: 0.3832 - cls_loss: 0.2502 - box_loss: 0.0027 - reg_l2_loss: 0.0730 - loss: 0.4562 - learning_rate: 0.0050 - gradient_norm: 2.4337 - val_det_loss: 0.4290 - val_cls_loss: 0.2542 - val_box_loss: 0.0035 - val_reg_l2_loss: 0.0730 - val_loss: 0.5020\n",
            "Epoch 51/100\n",
            "249/249 [==============================] - 74s 297ms/step - det_loss: 0.3849 - cls_loss: 0.2514 - box_loss: 0.0027 - reg_l2_loss: 0.0730 - loss: 0.4579 - learning_rate: 0.0048 - gradient_norm: 2.4782 - val_det_loss: 0.4257 - val_cls_loss: 0.2389 - val_box_loss: 0.0037 - val_reg_l2_loss: 0.0730 - val_loss: 0.4988\n",
            "Epoch 52/100\n",
            "249/249 [==============================] - 77s 310ms/step - det_loss: 0.3853 - cls_loss: 0.2509 - box_loss: 0.0027 - reg_l2_loss: 0.0730 - loss: 0.4583 - learning_rate: 0.0047 - gradient_norm: 2.4522 - val_det_loss: 0.4467 - val_cls_loss: 0.2385 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0730 - val_loss: 0.5197\n",
            "Epoch 53/100\n",
            "249/249 [==============================] - 72s 290ms/step - det_loss: 0.3781 - cls_loss: 0.2477 - box_loss: 0.0026 - reg_l2_loss: 0.0730 - loss: 0.4511 - learning_rate: 0.0045 - gradient_norm: 2.5075 - val_det_loss: 0.4949 - val_cls_loss: 0.2592 - val_box_loss: 0.0047 - val_reg_l2_loss: 0.0730 - val_loss: 0.5680\n",
            "Epoch 54/100\n",
            "249/249 [==============================] - 71s 286ms/step - det_loss: 0.3778 - cls_loss: 0.2458 - box_loss: 0.0026 - reg_l2_loss: 0.0730 - loss: 0.4509 - learning_rate: 0.0044 - gradient_norm: 2.3865 - val_det_loss: 0.3915 - val_cls_loss: 0.2224 - val_box_loss: 0.0034 - val_reg_l2_loss: 0.0730 - val_loss: 0.4645\n",
            "Epoch 55/100\n",
            "249/249 [==============================] - 101s 407ms/step - det_loss: 0.3614 - cls_loss: 0.2336 - box_loss: 0.0026 - reg_l2_loss: 0.0730 - loss: 0.4345 - learning_rate: 0.0042 - gradient_norm: 2.3805 - val_det_loss: 0.4711 - val_cls_loss: 0.2485 - val_box_loss: 0.0045 - val_reg_l2_loss: 0.0730 - val_loss: 0.5441\n",
            "Epoch 56/100\n",
            "135/249 [===============>..............] - ETA: 29s - det_loss: 0.3793 - cls_loss: 0.2506 - box_loss: 0.0026 - reg_l2_loss: 0.0730 - loss: 0.4524 - learning_rate: 0.0041 - gradient_norm: 2.8063"
          ]
        }
      ],
      "source": [
        "model = object_detector.create(train_ds, model_spec=spec, batch_size=8, train_whole_model=True, validation_data=val_ds,epochs = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm_UULdW7A9T"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFobSHfOELzP"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='/content/drive/MyDrive/Fruits/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH0JaqbNCJ_I"
      },
      "outputs": [],
      "source": [
        "model.evaluate_tflite('deneme.tflite', train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZgrd7Xo-dzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0098028-063f-4663-99fd-8205f97672bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.9.2 in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (3.19.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.50.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (4.1.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (14.0.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (2.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (2.1.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (2.9.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (0.28.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.21.6)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (2.9.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.12)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2.14.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow==2.9.2) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.9.2\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU2FbmBT417D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5232611-7494-4cbb-8e08-b783e8926c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python==4.5.5.64\n",
            "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.5 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from opencv-python==4.5.5.64) (1.21.6)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.6.0.66\n",
            "    Uninstalling opencv-python-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-4.6.0.66\n",
            "Successfully installed opencv-python-4.5.5.64\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python==4.5.5.64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT7mtSTA-e3h"
      },
      "outputs": [],
      "source": [
        "#@title Load the trained TFLite model and define some visualization functions\n",
        "\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "model_path = 'best-fp16.tflite'\n",
        "\n",
        "classes = ['Apple',\n",
        "             'Apricot',\n",
        "             'Banana',\n",
        "             'Grapefruit',\n",
        "             'Lemon',\n",
        "             'Mango',\n",
        "             'Melon',\n",
        "             'Orange',\n",
        "             'Pear',\n",
        "             'Persimmone',\n",
        "             'Pineapple',\n",
        "             'Plum',\n",
        "             'Pomegranade',\n",
        "             'Watermelon']\n",
        "\n",
        "\n",
        "# Define a list of colors for visualization\n",
        "COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)\n",
        "\n",
        "def preprocess_image(image_path, input_size):\n",
        "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
        "  img = tf.io.read_file(image_path)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
        "  original_image = img\n",
        "  resized_img = tf.image.resize(img, input_size)\n",
        "  resized_img = resized_img[tf.newaxis, :]\n",
        "  resized_img = tf.cast(resized_img, dtype=tf.uint8)\n",
        "  return resized_img, original_image\n",
        "\n",
        "\n",
        "def detect_objects(interpreter, image, threshold):\n",
        "  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n",
        "\n",
        "  signature_fn = interpreter.get_signature_runner()\n",
        "\n",
        "  # Feed the input image to the model\n",
        "  output = signature_fn(images=image)\n",
        "\n",
        "  # Get all outputs from the model\n",
        "  count = int(np.squeeze(output['output_0']))\n",
        "  scores = np.squeeze(output['output_1'])\n",
        "  classes = np.squeeze(output['output_2'])\n",
        "  boxes = np.squeeze(output['output_3'])\n",
        "\n",
        "  results = []\n",
        "  for i in range(count):\n",
        "    if scores[i] >= threshold:\n",
        "      result = {\n",
        "        'bounding_box': boxes[i],\n",
        "        'class_id': classes[i],\n",
        "        'score': scores[i]\n",
        "      }\n",
        "      results.append(result)\n",
        "  return results\n",
        "\n",
        "\n",
        "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
        "  \"\"\"Run object detection on the input image and draw the detection results\"\"\"\n",
        "  # Load the input shape required by the model\n",
        "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
        "\n",
        "  # Load the input image and preprocess it\n",
        "  preprocessed_image, original_image = preprocess_image(\n",
        "      image_path,\n",
        "      (input_height, input_width)\n",
        "    )\n",
        "\n",
        "  # Run object detection on the input image\n",
        "  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
        "\n",
        "  # Plot the detection results on the input image\n",
        "  original_image_np = original_image.numpy().astype(np.uint8)\n",
        "  for obj in results:\n",
        "    # Convert the object bounding box from relative coordinates to absolute\n",
        "    # coordinates based on the original image resolution\n",
        "    ymin, xmin, ymax, xmax = obj['bounding_box']\n",
        "    xmin = int(xmin * original_image_np.shape[1])\n",
        "    xmax = int(xmax * original_image_np.shape[1])\n",
        "    ymin = int(ymin * original_image_np.shape[0])\n",
        "    ymax = int(ymax * original_image_np.shape[0])\n",
        "\n",
        "    # Find the class index of the current object\n",
        "    class_id = int(obj['class_id'])\n",
        "\n",
        "    # Draw the bounding box and label on the image\n",
        "    color = [int(c) for c in COLORS[class_id]]\n",
        "    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "    # Make adjustments to make the label visible for all objects\n",
        "    y = ymin - 15 if ymin - 15 > 15 else ymin + 15\n",
        "    label = \"{}: {:.0f}%\".format(classes[class_id], obj['score'] * 100)\n",
        "    cv2.putText(original_image_np, label, (xmin, y),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  # Return the final image\n",
        "  original_uint8 = original_image_np.astype(np.uint8)\n",
        "  return original_uint8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNPtqp_v-tko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "3ce22892-ee68-42b2-df83-2163aa0e39ca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7d7db09b6d70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Run inference and draw detection result on the local copy of the original file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m detection_result_image = run_odt_and_draw_results(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mTEMP_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0minterpreter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cd05dbd3dcbf>\u001b[0m in \u001b[0;36mrun_odt_and_draw_results\u001b[0;34m(image_path, interpreter, threshold)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;31m# Run object detection on the input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpreter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessed_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;31m# Plot the detection results on the input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cd05dbd3dcbf>\u001b[0m in \u001b[0;36mdetect_objects\u001b[0;34m(interpreter, image, threshold)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0;31m# Feed the input image to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;31m# Get all outputs from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         raise ValueError('Invalid Input name (%s) for SignatureDef' %\n\u001b[0m\u001b[1;32m    246\u001b[0m                          input_name)\n\u001b[1;32m    247\u001b[0m       self._interpreter_wrapper.ResizeInputTensor(\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid Input name (images) for SignatureDef"
          ]
        }
      ],
      "source": [
        "#@title Run object detection and show the detection results\n",
        "\n",
        "INPUT_IMAGE_URL = \"https://pictures.grocerapps.com/original/grocerapp-pineapple--5e6d047342012.png\" #@param {type:\"string\"}\n",
        "DETECTION_THRESHOLD = 0.3 #@param {type:\"number\"}\n",
        "\n",
        "TEMP_FILE = '/tmp/image.png'\n",
        "\n",
        "!wget -q -O $TEMP_FILE $INPUT_IMAGE_URL\n",
        "im = Image.open(TEMP_FILE)\n",
        "im.thumbnail((512, 512), Image.ANTIALIAS)\n",
        "im.save(TEMP_FILE, 'PNG')\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Run inference and draw detection result on the local copy of the original file\n",
        "detection_result_image = run_odt_and_draw_results(\n",
        "    TEMP_FILE,\n",
        "    interpreter,\n",
        "    threshold=DETECTION_THRESHOLD\n",
        ")\n",
        "\n",
        "# Show the detection result\n",
        "Image.fromarray(detection_result_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "import torch\n",
        "\n",
        "model = torch.hub.load('fatihatac/yoloV5-custom', 'yolov5s')  # yolov5n - yolov5x6 or custom\n",
        "im = 'https://media.istockphoto.com/id/810147810/photo/fruit-bowl-isolated.jpg?s=612x612&w=0&k=20&c=F2zDR2U5EHDK_FUWGjE3mkhTHuZlupmMHsl1kLLjSJg='  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "results = model(im)  # inference\n",
        "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "u2BTD9mL2Fjm",
        "outputId": "b5b11b01-43c8-47d5-de42-fcffb8c7ed5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/fatihatac/yoloV5-custom/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e48b80fd1194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fatihatac/yoloV5-custom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yolov5s'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# yolov5n - yolov5x6 or custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://media.istockphoto.com/id/810147810/photo/fruit-bowl-isolated.jpg?s=612x612&w=0&k=20&c=F2zDR2U5EHDK_FUWGjE3mkhTHuZlupmMHsl1kLLjSJg='\u001b[0m  \u001b[0;31m# file, Path, PIL.Image, OpenCV, nparray, list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m                                            verbose=verbose, skip_validation=skip_validation)\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0mhubconf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhubconf_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODULE_HUBCONF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m     \u001b[0mhub_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_import_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODULE_HUBCONF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhubconf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_import_module\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.cache/torch/hub/fatihatac_yoloV5-custom_main/hubconf.py'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}